---
title: "Causal Inference for Computational Social Science"
subtitle: "Regime Change Causal Modeling with V-Dem"
author: 
  - name: "Troy Cheng, Hongzhe Wang"
    email: yc1317@georgetown.edu
    affiliation: Georgetown University
    corresponding: true
df-print: kable
title-block-banner: "#0a0e1a"
title-block-banner-color: "#4DB8FF"
execute:
  warning: false
date: 2025-07-23
date-modified: last-modified
format:
  html:
    embed-resources: true
    toc: true                 
    toc-title: "Contents"     
    toc-location: right       
    number-sections: true
    number-depth: 3       
    smooth-scroll: true       
    css: troystyle.css 
    code-overflow: wrap
include-in-header:
  text: |
    <link rel="shortcut icon" href="assets/gu.ico" type="image/x-icon">           
highlight-style: nord       
engine: knitr
---

```{r}
#| label: setup-python
#| message: false
#| include: false
library(reticulate)

need <- c("pymc", "arviz", "numpy", "graphviz", "ipython")
miss <- need[!sapply(need, py_module_available)]
if (length(miss)) {
  if (!nzchar(Sys.getenv("SSL_CERT_FILE"))) Sys.unsetenv("SSL_CERT_FILE")
  py_install(miss, pip = TRUE)
}

```

# Note:

Hi, Prof. Jeff, I encountered a rendering issue, I'll fix this file in 8 hours.

# Introduction

This project is a practice of causal inference, aiming to complete the journey from correlation to causation in empirical social science research. The study investigates macro-political transformations—particularly regime changes—through a causal lens grounded in computational methods. The analysis relies on [the Varieties of Democracy (V-Dem) dataset](https://github.com/vdeminstitute/vdemdata), one of the most comprehensive global sources on political regimes and democratic institutions. Covering nearly every country from the 18th century to the present, V-Dem provides detailed yearly indicators across political, economic, and social dimensions, allowing for the historical tracking of institutional change.

The analysis is guided by four core research questions:

RQ: What kinds of factors cause a country to undergo a regime change?

We study macro-political transformations with a causal lens. The unit is country–year. To avoid temporal leakage, the outcome is whether a regime change occurs in year t+1 given information available by the end of year t. We use V-Dem for yearly indicators. Conceptually, we posit that shocks (economic, conflict), mobilization (protest), repression, and institutional constraints shape the hazard of regime change, with possible unobserved country-level traits.

# Import Vdem Data using its R Package

```{r}
# Install V-Dem data package:
# install.packages("devtools")
# devtools::install_github("vdeminstitute/vdemdata")

library(vdemdata)
```

# Operationalizing Regime Change

V-Dem includes a variable, `v2reginfo`, that labels distinct historical phases within the same political entity (e.g., “Soviet Russia,” “USSR under Stalin,” “Post-Stalin USSR”) as separate regimes. While this fine-grained coding is valuable for phase-typed institutional histories, in this study I adopt a broader conception of “regime” tied to the persistence of the overarching political entity. Concretely, I operationalize regime change as a within-country shift in `histname` across adjacent years. This choice treats leader-centered or intra-regime episodes (that `v2reginfo` may separate) as continuity rather than change, while recognizing foundational transformations that coincide with historical-state redefinitions (e.g., mergers, dissolutions, refoundings). I report sensitivity analyses that compare this `histname`-based indicator to a `v2reginfo`-based alternative to gauge how inferences depend on the operationalization.

```{r}

#| label: make-regime-change
#| message: false
library(tidyverse)
library(stringr)
library(tidyr)

# 2.1 标准化 histname，避免大小写/空白导致的伪变化
vdem_change <- vdem %>%
  arrange(country_id, year) %>%
  mutate(histname_std = str_squish(str_to_lower(histname)))

# 2.2 基于 histname 的相邻年差异，定义当年是否“发生变迁”
vdem_change <- vdem_change %>%
  group_by(country_id) %>%
  mutate(
    regime_change_histname = as.integer(!is.na(histname_std) & histname_std != lag(histname_std))
  ) %>%
  ungroup() %>%
  mutate(regime_change_histname = replace_na(regime_change_histname, 0L))

# 2.3 面向预测：构造 Y_{t+1}（用 t 年特征预测 t+1 年是否变迁）
vdem_change <- vdem_change %>%
  group_by(country_id) %>%
  mutate(y_t1_histname = replace_na(lead(regime_change_histname, 1), 0L)) %>%
  ungroup()

```

```{r}
# 3.1 变迁的总体比例（基准率）
mean(vdem_change$regime_change_histname, na.rm = TRUE)

# 3.2 随机看几条发生变迁的记录（是否合理）
vdem_change %>%
  filter(regime_change_histname == 1) %>%
  select(country_name, year, histname) %>%
  head(10)
```

把 v2regendtype 的分布看清楚——既看总体分布，也看发生变迁（你用 y_t1_histname==1）时下一年的“结束类型”分布。只做这一步，先不建模。

```{r}
#| label: regendtype-distribution
#| message: false
library(dplyr)
library(tidyr)

# 1) 建立代码本（codebook → 标签映射）
regend_map <- tibble::tibble(
  v2regendtype = 0:13,
  regend_label = c(
    "Military coup d’état",                                   # 0
    "Coup by non-military groups",                            # 1
    "Self-coup (autogolpe)",                                  # 2
    "Assassination of leader (non-coup)",                     # 3
    "Natural death of leader",                                # 4
    "Loss in civil war",                                      # 5
    "Loss in inter-state war",                                # 6
    "Foreign intervention (non inter-state loss)",            # 7
    "Popular uprising",                                       # 8
    "Liberalization/democratization guided by leaders",       # 9
    "Other directed transformation under leaders",            # 10
    "Liberalization/democratization w/o leader guidance",     # 11
    "Other process (not 1–11)",                               # 12
    "Regime still exists"                                     # 13
  )
)

# 2) 总体分布（不区分是否发生变迁）
overall_dist <- vdem_change %>%
  filter(!is.na(v2regendtype)) %>%
  count(v2regendtype, name = "n") %>%
  left_join(regend_map, by = "v2regendtype") %>%
  mutate(p = n / sum(n)) %>%
  arrange(v2regendtype)

print(overall_dist)

# 3) 与你的“t→t+1 变迁”对齐：取下一年的结束类型（regend_t1）
vdem_change <- vdem_change %>%
  group_by(country_id) %>%
  mutate(regend_t1 = dplyr::lead(v2regendtype, 1)) %>%
  ungroup()

# 仅在 y_t1_histname == 1 的行里看分布（且排除 code=13 “still exists”）
change_event_dist <- vdem_change %>%
  filter(y_t1_histname == 1, !is.na(regend_t1), regend_t1 != 13) %>%
  count(regend_t1, name = "n") %>%
  left_join(regend_map, by = c("regend_t1" = "v2regendtype")) %>%
  mutate(p = n / sum(n)) %>%
  arrange(desc(p))

print(change_event_dist)

# 4) 两个极简检查
n_change_rows <- sum(vdem_change$y_t1_histname == 1, na.rm = TRUE)
n_labeled_events <- sum(vdem_change$y_t1_histname == 1 & !is.na(vdem_change$regend_t1) & vdem_change$regend_t1 != 13)
cat("# of t+1 change rows:", n_change_rows, "\n")
cat("# of t+1 rows with a non-13 end-type label:", n_labeled_events, "\n")


```

## 步骤 A（R → 准备 y 和先验 α, β）

放在 Python 块之前；它只做三件事：从 vdem_change 构造 y（t+1 是否以 coup 收场）、计算经验比例 p0、给出先验强度 m 和 alpha, beta。

```{r}

#| label: r-make-y-and-prior
# 用 regend_t1 构造二元 y：{0,1,2}=1；其它且≠13=0；13(仍存在)丢弃
y <- with(vdem_change, ifelse(regend_t1 %in% c(0,1,2), 1L,
                       ifelse(!is.na(regend_t1) & regend_t1 != 13, 0L, NA_integer_)))
y <- y[!is.na(y)]            # 丢弃 NA
y <- as.integer(y)

# 经验比例（先验中心）
p0 <- mean(y)                # 例如 0.08 左右（你的数据会自动算）
m  <- 20                     # 等效样本量（先小点；后续可调 50/100）
alpha <- m * p0
beta  <- m * (1 - p0)
N <- length(y)

# 小检查
length(y); mean(y); alpha; beta

```

在 R 里和 y 对齐一个自变量 x_attempt（0/1）：

```{r}
# 放在 r-make-y-and-prior 之后
#| label: r-make-x-attempt
library(dplyr)

df_yx <- vdem_change %>%
  mutate(
    y = case_when(
      regend_t1 %in% c(0,1,2) ~ 1L,
      !is.na(regend_t1) & regend_t1 != 13 ~ 0L,
      TRUE ~ NA_integer_
    ),
    x_attempt = case_when(
      !is.na(e_pt_coup_attempts) & e_pt_coup_attempts > 0 ~ 1L,
      !is.na(e_pt_coup_attempts) & e_pt_coup_attempts == 0 ~ 0L,
      TRUE ~ NA_integer_  # ← NA 保留
    )
  ) %>%
  filter(!is.na(y)) %>%
  tidyr::drop_na(x_attempt) %>%
  select(y, x_attempt)

# 传给 Python
y <- as.integer(df_yx$y)
x <- as.integer(df_yx$x_attempt)
N <- length(y)

# 看一下两组样本量（有/无企图）
table(x)

```

下面这个 **R 代码块**放在你现在的 `r-make-x` 之后（或者至少放在所有 Python 块之前）。为了不影响你已有的 baseline，我们用全新的对象名：`y_star / x_attempt / alpha_star / beta_star / N_star`。

```{r}

#| label: r-make-y-star
library(dplyr)

# Y*_{t+1}: 次年是否以政变方式结束
# 1 = regend_t1 ∈ {0,1,2}; 0 = 其它所有非缺失（包括“仍存在”=13，以及非政变结束）
y_star <- with(vdem_change, ifelse(
  regend_t1 %in% c(0,1,2), 1L,
  ifelse(!is.na(regend_t1), 0L, NA_integer_)
))

# 与 attempt 对齐：e_pt_coup_attempts 在 1950+ 才有，丢弃 NA
attempts <- vdem_change$e_pt_coup_attempts
keep <- !is.na(y_star) & !is.na(attempts)

y_star    <- as.integer(y_star[keep])
x_attempt <- as.integer(attempts[keep] > 0)  # 1=当年有政变企图，0=没有
N_star    <- length(y_star)

# 先验中心：用全样本的平均当作先验中心（后面可换成 train 集）
p0_star    <- mean(y_star)
m_star     <- 20
alpha_star <- m_star * p0_star
beta_star  <- m_star * (1 - p0_star)

# 小检查（请把这两行的输出贴给我）
mean(y_star); table(x_attempt)

```

把这段放在上面 R 块**后面**即可（它只用到 `r.y_star / r.x_attempt / r.alpha_star / r.beta_star`）。

```{python}
#| label: py-y-star-conditional
import numpy as np
rng = np.random.default_rng(0)

y_star    = np.array(r.y_star, dtype="int64")
x_attempt = np.array(r.x_attempt, dtype="int64")
alpha     = float(r.alpha_star)
beta      = float(r.beta_star)

def group_stats(mask, name):
    y = y_star[mask]
    n = len(y); s = int(y.sum())
    prior_mean = alpha/(alpha+beta)
    post_mean  = (alpha + s)/(alpha + beta + n)
    obs_mean   = y.mean()
    return {"group": name, "n": n,
            "prior_mean": round(float(prior_mean),4),
            "obs_mean":   round(float(obs_mean),4),
            "post_mean":  round(float(post_mean),4)}

out = [group_stats(x_attempt==1, "attempt=1"),
       group_stats(x_attempt==0, "attempt=0")]
print(out)

# 不确定性：后验抽样求区间与差值概率
def post_draws(mask, size=40000):
    y = y_star[mask]
    n = len(y); s = int(y.sum())
    a = alpha + s; b = beta + (n - s)
    return rng.beta(a, b, size=size)

d1 = post_draws(x_attempt==1)
d0 = post_draws(x_attempt==0)
diff = d1 - d0

print({
    "diff_mean": float(diff.mean()),
    "Pr(diff>0)": float((diff>0).mean()),
    "diff_ci95": tuple(np.round(np.quantile(diff, [0.025, 0.975]), 4))
})



```

条件版解析（两组的 prior/obs/post）

```{python}
#| label: py-conditional-analytic
import numpy as np

y = np.array(r.y, dtype="int64")
x = np.array(r.x, dtype="int64")
alpha = float(r.alpha); beta = float(r.beta)

def stats(mask, name):
    y_g = y[mask]; n = len(y_g); s = int(y_g.sum())
    prior_mean = alpha/(alpha+beta)
    post_mean  = (alpha + s)/(alpha + beta + n)   # Beta–Bernoulli 共轭后验均值
    obs_mean   = y_g.mean() if n>0 else np.nan
    return {"group": name, "n": n,
            "prior_mean": round(float(prior_mean),4),
            "obs_mean":   round(float(obs_mean),4),
            "post_mean":  round(float(post_mean),4)}

out = [stats(x==1, "attempt=1"), stats(x==0, "attempt=0")]
print(out)
print({"posterior_diff": round(out[0]["post_mean"] - out[1]["post_mean"], 4)})


```

我们用 Beta 共轭的后验抽样，给两组各自的 95% 区间，并给出“差值\>0 的后验概率”。把下面这段 放在你刚打印两组均值的 Python 块后面 即可：

```{python}
#| label: py-conditional-intervals
import numpy as np
rng = np.random.default_rng(0)

y = np.array(r.y, dtype="int64")
x = np.array(r.x, dtype="int64")
alpha = float(r.alpha); beta = float(r.beta)

def post_draws(mask, size=50000):
    y_g = y[mask]
    n = len(y_g); s = int(y_g.sum())
    a = alpha + s
    b = beta  + (n - s)
    return rng.beta(a, b, size=size)

d1 = post_draws(x==1)   # attempt=1
d0 = post_draws(x==0)   # attempt=0
diff = d1 - d0

def summarize(d):
    return {
        "mean": float(d.mean()),
        "ci90": tuple(np.round(np.quantile(d, [0.05, 0.95]), 4)),
        "ci95": tuple(np.round(np.quantile(d, [0.025, 0.975]), 4)),
    }

print({
    "attempt=1": summarize(d1),
    "attempt=0": summarize(d0),
    "diff_mean": float(diff.mean()),
    "Pr(diff>0)": float((diff > 0).mean()),
    "diff_ci95": tuple(np.round(np.quantile(diff, [0.025, 0.975]), 4)),
})

```

## 步骤 B（Python → 画PGM并落地成 SVG 包含进 HTML）

```{python}
#| label: py-pgm-beta-bern
import numpy as np, pymc as pm

# 从 R 取数
y = np.array(r.y, dtype="int64")
alpha = float(r.alpha)
beta = float(r.beta)
N = int(r.N)

# 给模型声明 plate
coords = {"obs_id": np.arange(N)}
with pm.Model(coords=coords) as beta_bern:
    # 顶部：Beta先验
    p_coup = pm.Beta("p_coup", alpha=alpha, beta=beta)
    # 底部：观测数据（带 plate）
    y_obs = pm.Bernoulli("saycoup_obs", p=p_coup, observed=y, dims="obs_id")

# 生成 pgm_base.svg 并清理中间文件
pm.model_to_graphviz(beta_bern).render(filename="pgm_base", format="svg", cleanup=True)

```

![](pgm_base.svg)

现在的 baseline **只有一个全局概率** pcoupp\_{\text{coup}}pcoup​，它回答的是：

> “在所有 *会在 t+1 年结束* 的政体中，‘以政变方式结束’的大致占比是多少？”

它**没有**利用任何 t 年的信息（比如是否出现政变企图、内战、抗议等）。因此它**不区分情境**，把所有国家–年都“混在一起”估一个平均值。这对做基线/检查管用，但回答不了这类问题：

-   “当年**有政变企图**时，下一年以政变收场的概率是否更高？”

-   “**内战**的年份 vs 非内战年份，这个概率有什么差异？”

所以要加“条件变量”（covariate），是为了**把总体概率拆成情境化的概率**，也就是从

```{python}
#| label: dag_bad
from graphviz import Digraph
g = Digraph("dag_bad", format="svg"); g.attr(rankdir="LR")
g.node("A","A_t\n(coup attempts)", shape="ellipse")
g.node("C","C_t\n(conflicts, protest,\nrepression, shocks)", shape="ellipse")
g.node("U","U_i\n(country trait)", shape="ellipse")
g.node("E","E_{t+1}\n(any regime end)", shape="box")
g.node("Y","Y_{t+1}\n(coup vs not | E=1)", shape="box")
# edges
g.edge("A","E"); g.edge("C","E"); g.edge("U","E")
g.edge("C","Y"); g.edge("U","Y")
# conditioning (visual hint)
g.edge("A","Y", style="dashed", label="selection bias via E")
g.render("dag_bad", cleanup=True)

```

![](dag_bad.svg)

```{python}

#| label: dag_good
from graphviz import Digraph
g = Digraph("dag_good", format="svg"); g.attr(rankdir="LR")
g.node("A","A_t\n(coup attempts)", shape="ellipse")
g.node("C","C_t\n(conflicts, protest,\nrepression, shocks)", shape="ellipse")
g.node("U","U_i\n(country trait)", shape="ellipse")
g.node("T","W_t\n(year FE)", shape="ellipse")
g.node("Y","Y*_{t+1}\n(coup end next year?)", shape="box")
# edges
for s in ["A","C","U","T"]:
    g.edge(s,"Y")
g.edge("C","A"); g.edge("U","A")    # 混杂导致 A 与 Y 相关
g.render("dag_good", cleanup=True)


```

![](dag_good.svg)

## 步骤 C（Python → 最小的 prior–posterior 一致性检查：只打印 3 个数字

先不画图、不做复杂评估，只看先验均值 vs 后验均值 vs 观测均值，确认“信息更新”的方向对不对。

```{r}
#| label: opts
#| echo: false
RUN_MCMC <- FALSE 
DRAWS    <- 800
TUNE     <- 400
```

```{python}
#| label: stepC-posterior-check
import numpy as np, pymc as pm

# ——关键：兜底默认值，避免 r.RUN_MCMC 未定义时报错——
RUN_MCMC = bool(getattr(r, "RUN_MCMC", False))
DRAWS    = int(getattr(r, "DRAWS", 800))
TUNE     = int(getattr(r, "TUNE", 400))

y = np.array(r.y, dtype="int64")
alpha = float(r.alpha); beta = float(r.beta)

prior_mean = alpha/(alpha+beta)
obs_mean   = y.mean()

if RUN_MCMC:
    with beta_bern:
        idata = pm.sample(draws=DRAWS, tune=TUNE,
                          chains=2, cores=1, target_accept=0.9,
                          random_seed=42, compute_convergence_checks=False)
    post_mean = float(idata.posterior["p_coup"].values.mean())
    mode = "mcmc"
else:
    N = len(y); s = int(y.sum())
    post_mean = (alpha + s) / (alpha + beta + N)   # Beta–Bernoulli 共轭的解析后验均值
    mode = "analytic"

print({"mode": mode,
       "prior_mean": round(float(prior_mean),4),
       "obs_mean":   round(float(obs_mean),4),
       "post_mean":  round(float(post_mean),4)})


```

```{=html}
<script>
document.addEventListener("DOMContentLoaded", function() {
    const toc = document.getElementById("TOC");
    if (toc) {
        const sourceLink = document.createElement("div");
        sourceLink.innerHTML = `
            <div class="toc-source">
                <a href="https://github.com/troy-yu-cheng/causalinference-finalproj" 
                   target="_blank" 
                   class="github-button">
                   <svg xmlns="http://www.w3.org/2000/svg" 
                        viewBox="0 0 24 24" 
                        width="16" 
                        height="16" 
                        fill="currentColor"
                        style="vertical-align: middle; margin-right: 5px;">
                     <path d="M12 0C5.373 0 0 5.373 0 12c0 5.303 3.438 9.8 8.207 11.387.6.113.82-.26.82-.577v-2.157c-3.338.726-4.033-1.416-4.033-1.416-.546-1.386-1.332-1.756-1.332-1.756-1.09-.745.083-.73.083-.73 1.205.084 1.84 1.237 1.84 1.237 1.07 1.832 2.807 1.303 3.492.996.108-.774.418-1.303.76-1.602-2.665-.3-5.466-1.332-5.466-5.93 0-1.311.468-2.382 1.237-3.222-.124-.302-.536-1.52.118-3.163 0 0 1.008-.322 3.3 1.23a11.516 11.516 0 0 1 3.002-.403 11.486 11.486 0 0 1 3.002.403c2.292-1.552 3.3-1.23 3.3-1.23.654 1.644.242 2.861.118 3.163.77.84 1.236 1.911 1.236 3.222 0 4.61-2.807 5.627-5.48 5.922.43.372.812 1.103.812 2.222v3.293c0 .321.218.694.825.576C20.565 21.796 24 17.3 24 12 24 5.373 18.627 0 12 0z"/>
                   </svg>
                   View source
                </a>
            </div>
        `;
        toc.appendChild(sourceLink);
    }
});
</script>
```
